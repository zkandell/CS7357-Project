{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This currently does not function, in the middle of a rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "# Get pandas for data manipulation\n",
    "import pandas as pd\n",
    "# Import nltk for text processing\n",
    "import nltk\n",
    "# Import os for file manipulation\n",
    "import os\n",
    "# Import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title  \\\n",
      "0          #1 Cheerleader Camp (2010) (V)   \n",
      "1                 #1 Serial Killer (2013)   \n",
      "2  #1 at the Apocalypse Box Office (2015)   \n",
      "3                             #137 (2011)   \n",
      "4                              #30 (2013)   \n",
      "\n",
      "                                                Plot  Action  Adventure  \\\n",
      "0  When they're hired to work at a cheerleading c...       0          0   \n",
      "1  Years of seething rage against the racism he's...       0          0   \n",
      "2  Jules is, self declared, the most useless pers...       0          0   \n",
      "3  #137 is a SCI/FI thriller about a girl, Marla,...       0          0   \n",
      "4  A bright and talented performer, Chelsea Johns...       0          0   \n",
      "\n",
      "   Biography  Comedy  Crime  Drama  Family  Fantasy  ...  Horror  Music  \\\n",
      "0          0       1      0      0       0        0  ...       0      0   \n",
      "1          0       0      0      0       0        0  ...       1      0   \n",
      "2          0       1      0      0       0        0  ...       0      0   \n",
      "3          0       0      0      0       0        0  ...       0      0   \n",
      "4          0       1      0      1       0        0  ...       0      0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
      "0        0        0        0       0      0         0    0        0  \n",
      "1        0        0        0       0      0         0    0        0  \n",
      "2        0        0        0       1      0         0    0        0  \n",
      "3        0        0        0       1      0         0    0        0  \n",
      "4        1        0        0       0      0         0    0        0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data from Datasets/onehotplotgenre.csv\n",
    "data = pd.read_csv(\"Datasets/onehotplotgenre.csv\")\n",
    "# Get the first 5 rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the plot column tokenized and lowercased\n",
    "tokenizeddf = data.copy()\n",
    "tokenizeddf['Plot'] = tokenizeddf['Plot'].apply(lambda x: nltk.word_tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title  \\\n",
      "0          #1 Cheerleader Camp (2010) (V)   \n",
      "1                 #1 Serial Killer (2013)   \n",
      "2  #1 at the Apocalypse Box Office (2015)   \n",
      "3                             #137 (2011)   \n",
      "4                              #30 (2013)   \n",
      "\n",
      "                                                Plot  Action  Adventure  \\\n",
      "0  [when, they, 're, hired, to, work, at, a, chee...       0          0   \n",
      "1  [years, of, seething, rage, against, the, raci...       0          0   \n",
      "2  [jules, is, ,, self, declared, ,, the, most, u...       0          0   \n",
      "3  [#, 137, is, a, sci/fi, thriller, about, a, gi...       0          0   \n",
      "4  [a, bright, and, talented, performer, ,, chels...       0          0   \n",
      "\n",
      "   Biography  Comedy  Crime  Drama  Family  Fantasy  ...  Horror  Music  \\\n",
      "0          0       1      0      0       0        0  ...       0      0   \n",
      "1          0       0      0      0       0        0  ...       1      0   \n",
      "2          0       1      0      0       0        0  ...       0      0   \n",
      "3          0       0      0      0       0        0  ...       0      0   \n",
      "4          0       1      0      1       0        0  ...       0      0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
      "0        0        0        0       0      0         0    0        0  \n",
      "1        0        0        0       0      0         0    0        0  \n",
      "2        0        0        0       1      0         0    0        0  \n",
      "3        0        0        0       1      0         0    0        0  \n",
      "4        1        0        0       0      0         0    0        0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizeddf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words:  515729\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the longest plot\n",
    "maxlen = tokenizeddf['Plot'].apply(len).max()\n",
    "\n",
    "# Get the set of all words in the plot column\n",
    "wordset = set()\n",
    "for plot in tokenizeddf['Plot']:\n",
    "    wordset.update(plot)\n",
    "# Get the number of unique words\n",
    "numwords = len(wordset)\n",
    "print(\"Number of unique words: \", numwords)\n",
    "\n",
    "# Create a dictionary that maps words to integers\n",
    "word2int = {word: i for i, word in enumerate(wordset)}\n",
    "\n",
    "# Function to convert a list of words to a list of integers\n",
    "def words2ints(words):\n",
    "    # Run through each word in the list\n",
    "    ints = []\n",
    "    for word in words:\n",
    "        # If the word is in the dictionary, add the integer to the list\n",
    "        if word in word2int:\n",
    "            ints.append(word2int[word])\n",
    "    return ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title  \\\n",
      "0          #1 Cheerleader Camp (2010) (V)   \n",
      "1                 #1 Serial Killer (2013)   \n",
      "2  #1 at the Apocalypse Box Office (2015)   \n",
      "3                             #137 (2011)   \n",
      "4                              #30 (2013)   \n",
      "\n",
      "                                                Plot  Action  Adventure  \\\n",
      "0  [488374, 93730, 21346, 418143, 475418, 396012,...       0          0   \n",
      "1  [374574, 96524, 156151, 12143, 247429, 48943, ...       0          0   \n",
      "2  [193678, 456847, 357459, 224798, 371110, 35745...       0          0   \n",
      "3  [296323, 501868, 456847, 405264, 156958, 33526...       0          0   \n",
      "4  [405264, 116557, 149640, 199627, 130841, 35745...       0          0   \n",
      "\n",
      "   Biography  Comedy  Crime  Drama  Family  Fantasy  ...  Horror  Music  \\\n",
      "0          0       1      0      0       0        0  ...       0      0   \n",
      "1          0       0      0      0       0        0  ...       1      0   \n",
      "2          0       1      0      0       0        0  ...       0      0   \n",
      "3          0       0      0      0       0        0  ...       0      0   \n",
      "4          0       1      0      1       0        0  ...       0      0   \n",
      "\n",
      "   Musical  Mystery  Romance  Sci-Fi  Sport  Thriller  War  Western  \n",
      "0        0        0        0       0      0         0    0        0  \n",
      "1        0        0        0       0      0         0    0        0  \n",
      "2        0        0        0       1      0         0    0        0  \n",
      "3        0        0        0       1      0         0    0        0  \n",
      "4        1        0        0       0      0         0    0        0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the plot column to a list of integers\n",
    "tokenizeddf['Plot'] = tokenizeddf['Plot'].apply(words2ints)\n",
    "\n",
    "print(tokenizeddf.head())\n",
    "\n",
    "# Pad the plot column with zeros to make all plots the same length\n",
    "def pad_plot(plot):\n",
    "    return plot + [0] * (maxlen - len(plot))\n",
    "\n",
    "tokenizeddf['Plot'] = tokenizeddf['Plot'].apply(pad_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Title  \\\n",
      "0          #1 Cheerleader Camp (2010) (V)   \n",
      "1                 #1 Serial Killer (2013)   \n",
      "2  #1 at the Apocalypse Box Office (2015)   \n",
      "3                             #137 (2011)   \n",
      "4                              #30 (2013)   \n",
      "\n",
      "                                                Plot  Action  \n",
      "0  [488374, 93730, 21346, 418143, 475418, 396012,...       0  \n",
      "1  [374574, 96524, 156151, 12143, 247429, 48943, ...       0  \n",
      "2  [193678, 456847, 357459, 224798, 371110, 35745...       0  \n",
      "3  [296323, 501868, 456847, 405264, 156958, 33526...       0  \n",
      "4  [405264, 116557, 149640, 199627, 130841, 35745...       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\2112378440.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  actiondf[\"Action\"] = le.fit_transform(actiondf[\"Action\"])\n"
     ]
    }
   ],
   "source": [
    "# Make a dataframe with just title, plot, and action columns\n",
    "# Going to try this out first on just action movies\n",
    "actiondf = tokenizeddf[['Title', 'Plot', 'Action']]\n",
    "print(actiondf.head())\n",
    "\n",
    "# Encode the action column with LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "actiondf[\"Action\"] = le.fit_transform(actiondf[\"Action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset class for the actiondata\n",
    "class GenreDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, genre):\n",
    "        self.plot = data[\"Plot\"].values\n",
    "        self.genre = data[genre].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.plot)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        plot = self.plot[i]\n",
    "        genre = self.genre[i]\n",
    "        return torch.tensor(plot, dtype=torch.long), torch.tensor(genre, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split the actiondf\n",
    "actiontrain, actiontest = train_test_split(actiondf, test_size=0.2, random_state=42)\n",
    "    \n",
    "# Create a GenreDataset object for the actiondata\n",
    "actiontraindataset = GenreDataset(actiontrain, \"Action\")\n",
    "actiontestdataset = GenreDataset(actiontest, \"Action\")\n",
    "\n",
    "# Create a DataLoader for the actiondataset\n",
    "actiontrainloader = torch.utils.data.DataLoader(actiontraindataset, batch_size=32, shuffle=True)\n",
    "actiontestloader = torch.utils.data.DataLoader(actiontestdataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RNN to classify the plots as action or not\n",
    "class GenreRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(GenreRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(1, x.size(0), hidden).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])        \n",
    "        return out\n",
    "\n",
    "# Set the hyperparameters\n",
    "embed = 128\n",
    "hidden = 128\n",
    "output = 2\n",
    "\n",
    "# Create the model\n",
    "actionmodel = GenreRNN(numwords, embed, hidden, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we'll train an RNN for each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a model\n",
    "def train_genre_rnn(genre, epochs, embed, hidden, output):\n",
    "    genremodel = GenreRNN(numwords, embed, hidden, output)\n",
    "    # Extract the relevant columns from the dataframe\n",
    "    genredf = tokenizeddf[['Title', 'Plot', genre]]\n",
    "    # Encode the genre column\n",
    "    genredf[genre] = le.fit_transform(genredf[genre])\n",
    "    # Train test split the data\n",
    "    # We won't use the test data in this function\n",
    "    genretrain, genretest = train_test_split(genredf, test_size=0.3, random_state=42)\n",
    "    # Create a GenreDataset object\n",
    "    genretraindataset = GenreDataset(genretrain, genre)\n",
    "    # Create a DataLoader\n",
    "    genretrainloader = torch.utils.data.DataLoader(genretraindataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(genremodel.parameters(), lr=0.001)\n",
    "\n",
    "    # Set the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Send the model to the device\n",
    "    genremodel.to(device)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        genremodel.train()\n",
    "        for plots, genres in genretrainloader:\n",
    "            # Send the data to the device\n",
    "            plots = plots.to(device)\n",
    "            genres = genres.to(device)\n",
    "            outputs = genremodel(plots)\n",
    "            loss = criterion(outputs, genres.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "    # Return the model\n",
    "    return genremodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "def save_model(model, genre):\n",
    "    if not os.path.exists(\"models/rnn\"):\n",
    "        os.makedirs(\"models/rnn\")\n",
    "    torch.save(model.state_dict(), f\"models/rnn/{genre}model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Action', 'Adventure', 'Biography', 'Comedy', 'Crime', 'Drama',\n",
      "       'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Musical', 'Mystery',\n",
      "       'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get all the genres\n",
    "genres = data.columns[2:]\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Action already exists\n",
      "Model for Adventure already exists\n",
      "Model for Biography already exists\n",
      "Model for Comedy already exists\n",
      "Model for Crime already exists\n",
      "Model for Drama already exists\n",
      "Model for Family already exists\n",
      "Model for Fantasy already exists\n",
      "Training model for History\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6839067935943604\n",
      "Epoch 2/5, Loss: 0.6818390488624573\n",
      "Epoch 3/5, Loss: 0.6849406957626343\n",
      "Epoch 4/5, Loss: 0.6859745383262634\n",
      "Epoch 5/5, Loss: 0.6828728914260864\n",
      "Training model for Horror\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6000033020973206\n",
      "Epoch 2/5, Loss: 0.6000033020973206\n",
      "Epoch 3/5, Loss: 0.626711905002594\n",
      "Epoch 4/5, Loss: 0.6178090572357178\n",
      "Epoch 5/5, Loss: 0.617808997631073\n",
      "Training model for Music\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6637182831764221\n",
      "Epoch 2/5, Loss: 0.6691501140594482\n",
      "Epoch 3/5, Loss: 0.6664342284202576\n",
      "Epoch 4/5, Loss: 0.6664342284202576\n",
      "Epoch 5/5, Loss: 0.6637182831764221\n",
      "Training model for Musical\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.8657522201538086\n",
      "Epoch 2/5, Loss: 0.881516695022583\n",
      "Epoch 3/5, Loss: 0.881516695022583\n",
      "Epoch 4/5, Loss: 0.8657522201538086\n",
      "Epoch 5/5, Loss: 0.881516695022583\n",
      "Training model for Mystery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7563462853431702\n",
      "Epoch 2/5, Loss: 0.7563462853431702\n",
      "Epoch 3/5, Loss: 0.7624415755271912\n",
      "Epoch 4/5, Loss: 0.7502509951591492\n",
      "Epoch 5/5, Loss: 0.7624415755271912\n",
      "Training model for Romance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.39846736192703247\n",
      "Epoch 2/5, Loss: 0.39846736192703247\n",
      "Epoch 3/5, Loss: 0.3515300452709198\n",
      "Epoch 4/5, Loss: 0.39846736192703247\n",
      "Epoch 5/5, Loss: 0.5862166881561279\n",
      "Training model for Sci-Fi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7445646524429321\n",
      "Epoch 2/5, Loss: 0.7500738501548767\n",
      "Epoch 3/5, Loss: 0.7555829882621765\n",
      "Epoch 4/5, Loss: 0.7555829882621765\n",
      "Epoch 5/5, Loss: 0.7555829882621765\n",
      "Training model for Sport\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6685041785240173\n",
      "Epoch 2/5, Loss: 0.6660020351409912\n",
      "Epoch 3/5, Loss: 0.6660020351409912\n",
      "Epoch 4/5, Loss: 0.6660020351409912\n",
      "Epoch 5/5, Loss: 0.6660020351409912\n",
      "Training model for Thriller\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.8748595714569092\n",
      "Epoch 2/5, Loss: 0.8568382859230042\n",
      "Epoch 3/5, Loss: 0.8027744889259338\n",
      "Epoch 4/5, Loss: 0.8568384051322937\n",
      "Epoch 5/5, Loss: 0.874859631061554\n",
      "Training model for War\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.4824155867099762\n",
      "Epoch 2/5, Loss: 0.42449700832366943\n",
      "Epoch 3/5, Loss: 0.42449700832366943\n",
      "Epoch 4/5, Loss: 0.453456312417984\n",
      "Epoch 5/5, Loss: 0.42449700832366943\n",
      "Training model for Western\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkand\\AppData\\Local\\Temp\\ipykernel_53880\\797772229.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genredf[genre] = le.fit_transform(genredf[genre])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7799854874610901\n",
      "Epoch 2/5, Loss: 0.7981731295585632\n",
      "Epoch 3/5, Loss: 0.7981731295585632\n",
      "Epoch 4/5, Loss: 0.7799856066703796\n",
      "Epoch 5/5, Loss: 0.7799856066703796\n"
     ]
    }
   ],
   "source": [
    "# For each genre, check if there's already a model\n",
    "# If not, train a model and save it\n",
    "for genre in genres:\n",
    "    if not os.path.exists(f\"models/rnn/{genre}model.pth\"):\n",
    "        print(f\"Training model for {genre}\")\n",
    "        model = train_genre_rnn(genre, 5, 128, 128, 2)\n",
    "        save_model(model, genre)\n",
    "    else:\n",
    "        print(f\"Model for {genre} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the genre scores for a plot\n",
    "# Returns a dictionary with the genre as the key and the score (0-1) as the value\n",
    "def predict_genres(plot):\n",
    "    # Tokenize and pad the plot\n",
    "    plot = nltk.word_tokenize(plot.lower())\n",
    "    plot = words2ints(plot)\n",
    "    plot = pad_plot(plot)\n",
    "    plot = torch.tensor(plot, dtype=torch.long).unsqueeze(0)\n",
    "    # Create a dictionary to store the scores\n",
    "    scores = {}\n",
    "    # For each genre, load the model and get the score\n",
    "    for genre in genres:\n",
    "        # Check if the model exists\n",
    "        if not os.path.exists(f\"models/rnn/{genre}model.pth\"):\n",
    "            print(f\"Model for {genre} does not exist\")\n",
    "            continue\n",
    "        print(f\"Predicting {genre}\")\n",
    "        model = GenreRNN(numwords, 128, 128, 2)\n",
    "        model.load_state_dict(torch.load(f\"models/rnn/{genre}model.pth\"))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get the output of the model\n",
    "            output = model(plot)\n",
    "            # Convert the output to a probability\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)\n",
    "            # Get the probability of the plot being in the genre\n",
    "            score = prob[0][1].item()\n",
    "            # Add the score to the dictionary\n",
    "            scores[genre] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Action\n",
      "Predicting Adventure\n",
      "Predicting Biography\n",
      "Predicting Comedy\n",
      "Predicting Crime\n",
      "Predicting Drama\n",
      "Predicting Family\n",
      "Predicting Fantasy\n",
      "Predicting History\n",
      "Predicting Horror\n",
      "Predicting Music\n",
      "Predicting Musical\n",
      "Predicting Mystery\n",
      "Predicting Romance\n",
      "Predicting Sci-Fi\n",
      "Predicting Sport\n",
      "Predicting Thriller\n",
      "Predicting War\n",
      "Predicting Western\n",
      "{'Action': 0.3445218503475189, 'Adventure': 0.6334119439125061, 'Biography': 0.5937089920043945, 'Comedy': 0.5941818356513977, 'Crime': 0.5683135986328125, 'Drama': 0.5384088158607483, 'Family': 0.5249367952346802, 'Fantasy': 0.4671383202075958, 'History': 0.49430134892463684, 'Horror': 0.4511418044567108, 'Music': 0.48513540625572205, 'Musical': 0.5858104825019836, 'Mystery': 0.5334867238998413, 'Romance': 0.2626238465309143, 'Sci-Fi': 0.5303011536598206, 'Sport': 0.4862709045410156, 'Thriller': 0.597869336605072, 'War': 0.3459392786026001, 'Western': 0.5498623847961426}\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Make a prediction for a plot\n",
    "plot = \"Luke Skywalker joins forces with a Jedi Knight, a cocky pilot, a Wookiee and two droids to save the galaxy from the Empire's world-destroying battle station, while also attempting to rescue Princess Leia from the mysterious Darth Vader.\"\n",
    "predictions = predict_genres(plot)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old stuff below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[263], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m actiondata \u001b[38;5;241m=\u001b[39m data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Reduce actiondata to only have the first 1000 rows\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#actiondata = actiondata.head(1000)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Tokenize the plot column\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m actiondata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlot\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mactiondata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPlot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get the first 5 rows of the actiondata\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(actiondata\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_treebank_word_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\zkand\\miniconda3\\lib\\site-packages\\nltk\\tokenize\\destructive.py:160\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[1;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[0;32m    157\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp, substitution \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPUNCTUATION:\n\u001b[1;32m--> 160\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Handles parentheses.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m regexp, substitution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPARENS_BRACKETS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make a dataframe that has only the title, plot, and action columns\n",
    "actiondata = data[[\"Title\", \"Plot\", \"Action\"]]\n",
    "# Get the first 5 rows of the actiondata\n",
    "print(actiondata.head())\n",
    "\n",
    "# Encode the action column with LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "actiondata[\"Action\"] = le.fit_transform(actiondata[\"Action\"])\n",
    "\n",
    "# Get the length of the longest plot (for padding later on)\n",
    "maxlen = actiondata[\"Plot\"].apply(len).max()\n",
    "\n",
    "# Get the set of all words in the plot column\n",
    "wordset = set()\n",
    "for plot in actiondata[\"Plot\"]:\n",
    "    wordset.update(plot)\n",
    "# Get the number of unique words\n",
    "numwords = len(wordset)\n",
    "print(\"Number of unique words:\", numwords)\n",
    "\n",
    "# Create a dictionary that maps words to integers\n",
    "word2int = {word: i for i, word in enumerate(wordset)}\n",
    "\n",
    "# Function to convert a list of words to a list of integers\n",
    "def words2ints(words):\n",
    "    return [word2int[word] for word in words]\n",
    "\n",
    "# Convert the plot column to a list of integers\n",
    "actiondata[\"Plot\"] = actiondata[\"Plot\"].apply(words2ints)\n",
    "\n",
    "# Get the first 5 rows of the actiondata\n",
    "print(actiondata.head())\n",
    "\n",
    "# Pad the plot column with zeros to make all plots the same length\n",
    "def pad_plot(plot):\n",
    "    return plot + [0] * (maxlen - len(plot))\n",
    "\n",
    "actiondata[\"Plot\"] = actiondata[\"Plot\"].apply(pad_plot)\n",
    "\n",
    "# Get the first 5 rows of the actiondata\n",
    "print(actiondata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset class for the actiondata\n",
    "class GenreDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, genre):\n",
    "        self.plot = data[\"Plot\"].values\n",
    "        self.genre = data[genre].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.plot)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        plot = self.plot[i]\n",
    "        genre = self.genre[i]\n",
    "        return torch.tensor(plot, dtype=torch.long), torch.tensor(genre, dtype=torch.float)\n",
    "    \n",
    "# Create a GenreDataset object for the actiondata\n",
    "actiondataset = GenreDataset(actiondata, \"Action\")\n",
    "\n",
    "# Create a DataLoader for the actiondataset\n",
    "actionloader = torch.utils.data.DataLoader(actiondataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([10155, 15944, 14626,  ...,     0,     0,     0]), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "# Create the RNN to classify the plots as action or not\n",
    "class GenreRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(GenreRNN, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h0 = torch.zeros(1, x.size(0), hidden).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])        \n",
    "        return out\n",
    "\n",
    "# Set the hyperparameters\n",
    "embed = 128\n",
    "hidden = 128\n",
    "output = 2\n",
    "\n",
    "# Create the model\n",
    "actionmodel = GenreRNN(numwords, embed, hidden, output)\n",
    "\n",
    "print(actiondataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.38106486201286316\n",
      "Epoch 2/10, Loss: 0.13124583661556244\n",
      "Epoch 3/10, Loss: 0.08345924317836761\n",
      "Epoch 4/10, Loss: 0.09120485931634903\n",
      "Epoch 5/10, Loss: 0.6385515332221985\n",
      "Epoch 6/10, Loss: 0.3833125829696655\n",
      "Epoch 7/10, Loss: 0.07289722561836243\n",
      "Epoch 8/10, Loss: 0.12186636030673981\n",
      "Epoch 9/10, Loss: 0.3818072974681854\n",
      "Epoch 10/10, Loss: 0.38340580463409424\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(actionmodel.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    actionmodel.train()\n",
    "    for plots, genres in actionloader:\n",
    "        outputs = actionmodel(plots)\n",
    "        loss = criterion(outputs, genres.long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(1)\n",
      "1\n",
      "29 correct out of 32\n"
     ]
    }
   ],
   "source": [
    "# Look at the first five plots and their predicted genres\n",
    "actionmodel.eval()\n",
    "with torch.no_grad():\n",
    "    for plots, genres in actionloader:\n",
    "        outputs = actionmodel(plots)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        #print(\"Predictions:\", preds)\n",
    "        #print(\"Actual:\", genres)\n",
    "        print((preds == genres)[0])\n",
    "        print((preds == genres)[0].sum())\n",
    "        print((preds == genres)[0].sum().item())\n",
    "        num_correct = (preds == genres).sum().item()\n",
    "        print(num_correct, \"correct out of\", len(genres))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916 1000\n",
      "Accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "actionmodel.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for plots, genres in actionloader:\n",
    "        outputs = actionmodel(plots)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += genres.size(0)\n",
    "        num_correct = (predicted == genres).sum().item()\n",
    "        correct += num_correct\n",
    "print(correct, total)\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
